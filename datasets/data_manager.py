from collections import defaultdict
import torch
import torch.distributed as dist

from torch.utils.data import Dataset, DataLoader
from PIL import Image
from tabulate import tabulate
from .build_dataset import build_dataset
from .sampler import build_sampler
from .transforms import build_transform


def train_collate_fn(batch):
    """Collate function for training data loader."""
    batch_dict = {}
    img_paths, aids, camids, viewids, imgs, domains = [], [], [], [], [], []
    for b_dict in batch:
        img_paths.append(b_dict["img_path"])
        aids.append(b_dict["aid"])
        camids.append(b_dict["camid"])
        viewids.append(b_dict["viewid"])
        imgs.append(b_dict["img"])
        domains.append(b_dict["domain"]) 
    
    batch_dict["img_paths"] = img_paths
    batch_dict["aids"] = torch.tensor(aids, dtype = torch.int64)
    batch_dict["camids"] = camids
    batch_dict["viewids"] = torch.tensor(viewids, dtype = torch.int64)
    batch_dict["imgs"] = torch.stack(imgs, dim = 0)
    batch_dict["domains"] = domains 

    return batch_dict


def test_collate_fn(batch):
    """Collate function for test data loader."""
    batch_dict = {}
    img_paths, aids, camids, viewids, imgs, domains = [], [], [], [], [], []
    for b_dict in batch:
        img_paths.append(b_dict["img_path"])
        aids.append(b_dict["aid"])
        camids.append(b_dict["camid"])
        viewids.append(b_dict["viewid"])
        imgs.append(b_dict["img"])
        domains.append(b_dict["domain"])  
    
    batch_dict["img_paths"] = img_paths
    batch_dict["aids"] = torch.tensor(aids, dtype = torch.int64)
    batch_dict["camids"] = camids
    batch_dict["viewids"] = torch.tensor(viewids, dtype = torch.int64)
    batch_dict["imgs"] = torch.stack(imgs, dim = 0)
    batch_dict["domains"] = domains  

    return batch_dict


def build_data_loader(
        cfg, 
        sampler_type = "RandomIdentitySampler", 
        data_source = None, 
        batch_size = 32, 
        transform = None, 
        is_train = True,
        source_domains = None
):
    if is_train:
        sampler = build_sampler(data_source = data_source, 
                                sampler_type = sampler_type, 
                                batch_size = batch_size, 
                                num_instances = cfg.DATALOADER.TRAIN.NUM_INSTANCES,
                                source_domains = source_domains)
        data_loader = DataLoader(
            dataset = DatasetWrapper(cfg = cfg, data_source = data_source, transform = transform, is_train = is_train), 
            batch_size = batch_size, 
            sampler = sampler, 
            num_workers = cfg.DATALOADER.NUM_WORKERS, 
            collate_fn = train_collate_fn
        )
    else:
        data_loader = DataLoader(
            dataset = DatasetWrapper(cfg = cfg, data_source = data_source, transform = transform, is_train = is_train), 
            batch_size = batch_size, 
            num_workers = cfg.DATALOADER.NUM_WORKERS, 
            collate_fn = test_collate_fn,
            shuffle=False
        )
    
    assert len(data_loader) > 0, "Empty data loader"
    return data_loader


class DataManager:
    def __init__(self, cfg):
        self.datasets = build_dataset(cfg)    # creates a list of datasets
        self.source_domains = cfg.DATASET.SOURCE_DOMAINS if hasattr(cfg.DATASET, 'SOURCE_DOMAINS') else []
        self.target_domains = cfg.DATASET.TARGET_DOMAINS if hasattr(cfg.DATASET, 'TARGET_DOMAINS') else []

        self.train_data = []
        self.gallery_data = []
        self.query_data = []

        for dataset in self.datasets:
            self.train_data.extend(dataset.train_data)
            self.gallery_data.extend(dataset.gallery_data)
            self.query_data.extend(dataset.query_data)


        # convert to global id
        train_global_ids = self.convert_to_global_id(self.train_data)
        test_global_ids = self.convert_to_global_id(self.query_data + self.gallery_data)

        transform_train = build_transform(cfg, is_train = True)
        transform_test = build_transform(cfg, is_train = False)
        
        self.data_loader_train = build_data_loader(
            cfg = cfg, 
            sampler_type = cfg.DATALOADER.TRAIN.SAMPLER, 
            data_source = self.train_data, 
            batch_size = cfg.DATALOADER.TRAIN.BATCH_SIZE, 
            transform = transform_train, 
            is_train = True,
            source_domains = self.get_source_domains
        )

        self.data_loader_test = build_data_loader(
            cfg = cfg, 
            data_source = self.query_data + self.gallery_data, 
            batch_size = cfg.DATALOADER.TEST.BATCH_SIZE, 
            transform = transform_test, 
            is_train = False,
        )

        
        self.len_query = len(self.query_data)

    @property
    def num_classes(self):
        num_classes_dict = {}
        for dataset in self.datasets:
            num_classes_dict[dataset.domain_label] = dataset.num_train_aids
        return num_classes_dict

    @property
    def get_num_train_images(self):
        return len(self.train_data)
    
    @property
    def get_source_domains(self):
        return self.source_domains

    @property
    def get_target_domains(self):
        return self.target_domains
    
    @property
    def get_num_train_camids(self):
        return self.dataset.num_train_cams
    
    @property
    def get_num_train_viewids(self):
        return self.dataset.num_train_views
    
    @property
    def get_num_gallery_images(self):
        return self.dataset.num_gallery_imgs
    
    @property
    def get_num_gallery_aids(self):
        return self.dataset.num_gallery_aids
    
    @property
    def get_num_gallery_camids(self):
        return self.dataset.num_gallery_cams
    
    @property
    def get_num_gallery_viewids(self):
        return self.dataset.num_gallery_views
    
    @property
    def get_num_query_images(self):
        return self.dataset.num_query_imgs
    
    @property
    def get_num_query_aids(self):
        return self.dataset.num_query_aids
    
    @property
    def get_num_query_camids(self):
        return self.dataset.num_query_cams
    
    @property
    def get_num_query_viewids(self):
        return self.dataset.num_query_views

    def convert_to_global_id(self, dataset):
        domain_to_aids = defaultdict(set)
        for d in dataset:
            # Each "d" is a Datum with fields aid (local id) and domain_label (int)
            domain_to_aids[d.domain_label].add(d.aid)

        domain_label_offsets = {}
        running_offset = 0
        for dom in sorted(domain_to_aids.keys()):
            domain_label_offsets[dom] = running_offset
            running_offset += len(domain_to_aids[dom])


        # Build globally unique class names using domain-specific offsets
        # Each global class id = local aid + offset(domain_label)
        global_ids = set()
        for d in dataset:
            global_id = domain_label_offsets[d.domain_label] + d.aid
            d.aid = global_id
            global_ids.add(global_id)
        return global_ids


class DatasetWrapper(Dataset):
    def __init__(self, cfg, data_source, transform = None, is_train = False):
        self.cfg = cfg
        self.data_source = data_source
        self.transform = transform
        self.is_train = is_train
    
    def __len__(self):
        return len(self.data_source)
    
    def __getitem__(self, idx):
        datum = self.data_source[idx]

        output = {
            "img_path": datum.img_path,
            "aid": datum.aid, 
            "camid": datum.camid, 
            "viewid": datum.viewid, 
            "domain": datum.domain_label 
        }

        img = Image.open(datum.img_path).convert("RGB")
        img = self.transform(img)
        output["img"] = img

        return output